{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper_code import *\n",
    "import numpy as np, os, sys, joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from team_code import get_features\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from resnet import ResNet, BasicBlock, Bottleneck\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "sys.path.append(os.path.abspath(\"../datasets\"))\n",
    "from physionet2021 import PhysioNet2021Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(header, recording, leads):\n",
    "    # Extract age.\n",
    "    age = get_age(header)\n",
    "    if age is None:\n",
    "        age = float('nan')\n",
    "\n",
    "    # Extract sex. Encode as 0 for female, 1 for male, and NaN for other.\n",
    "    sex = get_sex(header)\n",
    "    if sex in ('Female', 'female', 'F', 'f'):\n",
    "        sex = 0\n",
    "    elif sex in ('Male', 'male', 'M', 'm'):\n",
    "        sex = 1\n",
    "    else:\n",
    "        sex = float('nan')\n",
    "\n",
    "    print (age, sex)\n",
    "    # Reorder/reselect leads in recordings.\n",
    "    available_leads = get_leads(header)\n",
    "    indices = list()\n",
    "    for lead in leads:\n",
    "        i = available_leads.index(lead)\n",
    "        indices.append(i)\n",
    "    recording = recording[indices, :]\n",
    "\n",
    "    # Pre-process recordings.\n",
    "    adc_gains = get_adcgains(header, leads)\n",
    "    baselines = get_baselines(header, leads)\n",
    "    num_leads = len(leads)\n",
    "    for i in range(num_leads):\n",
    "        recording[i, :] = (recording[i, :] - baselines[i]) / adc_gains[i]\n",
    "\n",
    "    # Compute the root mean square of each ECG lead signal.\n",
    "    rms = np.zeros(num_leads, dtype=np.float32)\n",
    "    for i in range(num_leads):\n",
    "        x = recording[i, :]\n",
    "        rms[i] = np.sqrt(np.sum(x**2) / np.size(x))\n",
    "\n",
    "    return age, sex, rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = load_recording('../WFDB_CPSC2018_2/Q0002.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'E00001'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5ac5117dbe13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtraining_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhysioNet2021Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/physinet2021/datasets/physionet2021.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, fs, max_seq_len, ensure_equal_len, proc, records, simple_test)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx_to_key_rel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_length_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/physinet2021/datasets/physionet2021.py\u001b[0m in \u001b[0;36minitialize_length_references\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# store the lengths and sample counts for each of the records\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mlen_rn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_rn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_len_fs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfs_rn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mlen_resamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_rn\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfs_rn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'E00001'"
     ]
    }
   ],
   "source": [
    "params = {'batch_size': 64}\n",
    "\n",
    "data_directory = '../data/'\n",
    "training_set = PhysioNet2021Dataset(data_directory)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_set, **params)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "# print(\"Using {} device\".format(device))\n",
    "\n",
    "model = ResNet(\n",
    "        block =BasicBlock,\n",
    "        layers = [2,3,5,7],\n",
    "        in_channel = 12,\n",
    "        out_channel = 9\n",
    "        ).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sign loss\n",
    "sign_p = y - 2py + p^2    |y-p| < 0.5\n",
    "       = 1                |y-p| >= 0.5\n",
    "\n",
    "loss_fn = sign_p x nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_weight = torch.ones([9])  # All weights are equal to 1\n",
    "loss_fn = nn.BCEWithLogitsLoss(size_average = True) # need delete sigmoid\n",
    "loss_fn = nn.BCELoss(size_average = True)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_methods(labels, pred, threshold = 0.5):\n",
    "    \n",
    "# threshold = 0.5\n",
    "    probs_class = pred\n",
    "    probs_class[probs_class > threshold] = 0.99\n",
    "    probs_class[probs_class <= threshold] = 0.01\n",
    "    scalar_outputs = probs_class\n",
    "    print('- AUROC and AUPRC...')\n",
    "    auroc, auprc, auroc_classes, auprc_classes = compute_auc(labels, scalar_outputs)\n",
    "    print ('auroc:', auroc, 'auprc:', auprc)\n",
    "    \n",
    "    probs_class = pred\n",
    "    probs_class[probs_class > threshold] = 1\n",
    "    probs_class[probs_class <= threshold] = 0\n",
    "    binary_outputs = probs_class\n",
    "    print (binary_outputs)\n",
    "    print('- Accuracy...')\n",
    "    accuracy = compute_accuracy(labels, binary_outputs)\n",
    "    print ('accuracy:', accuracy)\n",
    "    print('- F-measure...')\n",
    "    f_measure, f_measure_classes = compute_f_measure(labels, binary_outputs)\n",
    "    print('f_measure:', f_measure)\n",
    "#     print('- Challenge metric...')\n",
    "#     challenge_metric = compute_challenge_metric(weights, labels, binary_outputs, classes, normal_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../evaluation-2021\"))\n",
    "from evaluate_model import *\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    labels_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for features in dataloader:\n",
    "            \n",
    "            X = features['sig']\n",
    "            age = features['age']\n",
    "            sex = features['sex']\n",
    "            labels = features['labels']\n",
    "            rn = features['record_name']\n",
    "            # Compute prediction error\n",
    "            age_numpy = age.numpy()\n",
    "            m = np.nanmean(age_numpy)\n",
    "            age_numpy = np.nan_to_num(age_numpy, nan=m)\n",
    "            age = torch.from_numpy(age_numpy)\n",
    "\n",
    "            age -= age.min()\n",
    "            age /= age.max()\n",
    "            demo_features = torch.stack([age, sex.double()], dim= 1)\n",
    "            demo_features = demo_features.float()\n",
    "            X, demo_features =  X.to(device), demo_features.to(device)\n",
    "            pred = model(X, demo_features)\n",
    "            labels = labels.int().numpy()\n",
    "            pred = pred.numpy()\n",
    "            \n",
    "            labels_list.append(labels)\n",
    "            pred_list.append(pred)\n",
    "            print (rn)\n",
    "            break\n",
    "#             return labels, pred\n",
    "    labels = np.concatenate(labels_list)\n",
    "    pred = np.concatenate(pred_list)\n",
    "    \n",
    "    evaluation_methods(labels, pred)\n",
    "#     return labels, pred  \n",
    "#             test_loss += loss_fn(pred, labels.float()).item()\n",
    "#             correct += (pred.argmax(1) == labels).type(torch.float).sum().item()\n",
    "#     test_loss /= size\n",
    "#     correct /= size\n",
    "#     print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    print (size)\n",
    "    for batch, features in enumerate(dataloader):\n",
    "        X = features['sig']\n",
    "        age = features['age']\n",
    "        sex = features['sex']\n",
    "        labels = features['labels']\n",
    "\n",
    "        age_numpy = age.numpy()\n",
    "        m = np.nanmean(age_numpy)\n",
    "        age_numpy = np.nan_to_num(age_numpy, nan=m)\n",
    "        age = torch.from_numpy(age_numpy)\n",
    "#         age\n",
    "        age -= age.min()\n",
    "        age /= age.max()\n",
    "        demo_features = torch.stack([age, sex.double()], dim= 1)\n",
    "        demo_features = demo_features.float()\n",
    "        X, demo_features, labels =  X.to(device), demo_features.to(device), labels.to(device)\n",
    "\n",
    "        try:\n",
    "            pred = model(X, demo_features)\n",
    "            loss = loss_fn(pred, labels.float())\n",
    "        except:\n",
    "            print (age_numpy, age)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twelve_leads = ('I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6')\n",
    "six_leads = ('I', 'II', 'III', 'aVR', 'aVL', 'aVF')\n",
    "three_leads = ('I', 'II', 'V2')\n",
    "two_leads = ('II', 'V5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(12,5000)\n",
    "sig = a[[twelve_leads.index(lead) for lead in two_leads], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_directory = '../WFDB_CPSC2018/'\n",
    "\n",
    "train_records, val_records = PhysioNet2021Dataset.split_names_cv(\n",
    "    data_directory, 5, 0\n",
    "    \n",
    ")\n",
    "ds = PhysioNet2021Dataset(\n",
    "    data_directory, max_seq_len=4096, records=val_records, ensure_equal_len=True, proc=0,leads = ('II', 'V5')\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    ds,\n",
    "    batch_size=64,\n",
    "    num_workers=0\n",
    "#     collate_fn=PhysioNet2020Dataset.collate_fn,\n",
    ")\n",
    "# ds = PhysioNet2021Dataset(\n",
    "#     data_directory, max_seq_len=4096, records=train_records, ensure_equal_len=True, proc=0\n",
    "# )\n",
    "# train_dl = DataLoader(\n",
    "#     ds,\n",
    "#     batch_size=64,\n",
    "#     num_workers=0\n",
    "# #     collate_fn=PhysioNet2020Dataset.collate_fn,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, features in enumerate(val_dl):\n",
    "        X = features['sig']\n",
    "        age = features['age']\n",
    "        sex = features['sex']\n",
    "        labels = features['labels']\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2, 4096])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_directory = '../WFDB_CPSC2018/'\n",
    "# testing_set = PhysioNet2021Dataset(data_directory)\n",
    "# test_dataloader = torch.utils.data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weijiesun/physinet2021/python-classifier-2021\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np, os, sys\n",
    "from team_code import load_twelve_lead_model, load_six_lead_model, load_three_lead_model, load_two_lead_model\n",
    "model_directory = \"./model\"\n",
    "twelve_lead_model = load_twelve_lead_model(model_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64}\n",
    "\n",
    "data_directory = '../data/'\n",
    "training_set = PhysioNet2021Dataset(data_directory)\n",
    "test_dataloader = torch.utils.data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PhysioNet2021Dataset(\n",
    "    data_directory, max_seq_len=4096, records=train_records, ensure_equal_len=True, proc=0\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    ds,\n",
    "    batch_size=64,\n",
    "    num_workers=0\n",
    "#     collate_fn=PhysioNet2020Dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = '../WFDB_CPSC2018_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "head, tail = os.path.split('Q0002.mat')\n",
    "root, extension = os.path.splitext(tail)\n",
    "output_file = os.path.join(output_directory, root + '.csv')\n",
    "# save_outputs(output_file, classes, labels, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../WFDB_CPSC2018_2/Q0002.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e19ef9c7c51d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sig'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "for batch, features in enumerate(dataloader):\n",
    "    X = features['sig']\n",
    "    age = features['age']\n",
    "    sex = features['sex']\n",
    "    labels = features['labels']\n",
    "    record_names = features['record_name']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 12, 4096])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "test() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a91a8ab22e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     train(train_dl, model, loss_fn, optimizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwelve_lead_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: test() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss(size_average=True)\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "#     train(train_dl, model, loss_fn, optimizer)\n",
    "    test(val_dl, twelve_lead_model, loss_fn)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
